# A database of urban resource management processes

\epigraph{``It is a capital mistake to theorize before one has data.''}{Sherlock Holmes in \emph{A Study in Scarlett} (Arthur Conan Doyle)}

\begin{tcolorbox}

A version of this chapter was published as: 
Tom Ravalde, James Keirstead, A database to facilitate a process-oriented approach to urban metabolism, \emph{Journal of Industrial Ecology}, doi: \url{http://dx.doi.org/10.1111/jiec.12429}. The `Approaches to urban metabolism' section of the paper was reworked into the literature review as Section \ref{sec:procs-in-UM}).

\end{tcolorbox}

```{r Setup, include=FALSE, results="hide", warning=FALSE}
opts_chunk$set(fig.path = "figures/", dev=c("cairo_pdf"), fig.pos='htbp', fig.width=5, fig.height=1.6, dpi=700, fig.show='hold', fig.lp="fig:", cache=FALSE, par=TRUE, echo=FALSE, results="hide", message=FALSE, warning=FALSE)

library(extrafont)
font_import(pattern="LinBiolinum")
```

To date, little attention has been paid to how the mix of resource management processes in the middle of a UM system affect the aggregate exchanges of material and energy with the external environment (Section \ref{sec:procs-in-UM}. This thesis hopes to address this gap by contributing a model which can optimise the mix and operation schedule of resource management processes in cities such, that they can work together to realise synergies which improve the metabolism of an area. However, to do this requires knowledge of the processes themselves, to act as inputs to the model. This Chapter identifies the resource conversion processes that can shape UM both now and in the future, and quantifies the resource consumption and production of each individual process, assembling this (and other) information into a database. The chapter then discusses applications of the database, including the main contribution to this thesis (which is to provide data for use in the optimisation model, thus forming part of Aim 1 of the research question), as well as other uses, which are facilitated by the model's public availability under an open-source license.

## Supporting fields of research

This background section introduces two research areas important to the assembly and use of the database: first, it takes a look at databases that currently exist which are similar to the one built here, as well as identifying a method to research the contents of such a database. After this, the subject of 'open data' is introduced -- particularly in relation to industrial ecology -- to show the benefits of making the database publicly available.

### Existing databases and technology scanning

There are a number of precedents for the proposed database; this section considers three of them in order to locate it within the existing landscape of tools. The first example comprises the 'technology roadmaps' published by the International Energy Agency [@IEA2015a]. These constitute comprehensive reports which outline important energy management technologies in view of climate change targets. For example, the technology roadmap for hydrogen and fuel cells outlines various hydrogen-using systems (e.g. fuel cell vehicles) and hydrogen-generating technologies (e.g. electrolysers), and includes prose-based descriptions of how the technologies work; tables of numerical values such as process capacity, efficiency, capital cost, and life expectancy; and the results of modelling which indicate the role hydrogen technologies could play in achieving targets [@IEA2015b]. 

Second, and also from the energy sector, is the Enipedia wiki, which is a collaborative environment that collects information about energy technologies, infrastructure, resources and other related issues [@Davis2015]. For example one section of Enipedia assembles a database of energy storage technologies, which notes their maturity, possible applications, operating efficiency, and lifetime expectancy, alongside descriptions of how they work. A third example covers a broader range of technologies, namely the ecoinvent life cycle inventory database which specifies the material and energy inputs and outputs for processes within energy supply, transport, packaging, electronics and other areas. The database is usually used to assess the environmental impact of supply chains to produce a good or service [@Weidema2013].

These examples have many useful applications, but none of them are geared towards the UM analysis of this thesis, which is attempting to optimise intersectoral synergies. For example, the IEA roadmaps and Enipedia are limited to energy management processes, and furthermore they do not record the non-energy flows associated with these processes, such as water and waste. The ecoinvent database is more comprehensive, in both the processes and flows recorded, but its focus is on product manufacturing supply chains, and thus it ignores processes important to urban metabolism such as drinking water treatment and HVAC systems. To facilitate process-oriented approaches to UM modelling, a new database is needed.

The building of the database will draw on the principles of technology scanning, which can be defined as "a way of taking a creative look at the world of technological developments and the cultural, regulatory, and business environments in which they emerge" [@Edgetech]. In general, it is used to support corporate strategy, by enabling industry to keep up-to-date with the current technology landscape, or to scan the horizon to identify emerging technologies [@VanWyk1997] (though the specific aims and methods vary on a case-by-case basis). As an example, in healthcare, researchers identified technologies which would improve clinical care in the most financially viable way through searching literature, databases and digital libraries, as well as consulting industrial experts [@AHRQ2015]. In another case study from the railroad industry, technology scanning was used to sift through many possible technologies to identify those which reduce costs or improve services,
in order to direct research and investment efforts [@Martland2002]. Martland et al.'s method involves first a "general search" to identify technologies, and second "technology mapping" which researches the performance and cost of each technology, and goes on to classify technologies according to maturity, functionality and other variables. Their scanning proved valuable as it uncovered technologies (such as nanotechnology) which had never before been identified in railroad technology strategies.

### Open data {#sec:open-data}

Open data is "data that can be freely used, re-used and redistributed by anyone -- subject only, at most, to the requirement to attribute and sharealike" [@OpenKnowledge2015], and is increasingly prevalent in academic research (Figure \ref{fig:open_data}). A high profile example is the Human Genome Project who placed all their human genomic sequence information in the public domain, so research would be of maximum societal benefit [@HUGO1996]. The term 'open data' first appeared in 1995, and was formally clarified in 2007 to incorporate three principles: "openness, participation and collaboration" [@Chignard2013]. Open data brings many benefits, including: opening up scientific enquiry, promoting new research, allowing verification of published results, and enabling research to go in directions not envisaged by the initial investigators [@Uhlir2007]. Added to this, making data open protects it from loss due to hardware malfunction, and also makes it useful as a teaching tool [@Roche2014].

When it comes to open data within Industrial Ecology (IE) specifically, @Davis2010 argues that the community needs to improve its data management between sub-disciplines, so that research findings can more effectively contribute to the sum total of IE knowledge. Nevertheless, there are a few examples, such as @Zhu2014 who provide an open data set from the European Pollutant Release and Transfer Register (E-PRTR) [@EPRTR2009], to identify the type and location of pollutant releases from over 30,000 industrial facilities. They propose that this information be coupled with a dataset of industrial process inputs for European facilities, to matchmake facilities, so that the waste outputs of one facility meet the input requirements of another. Other opensource IE datasets are listed at \url{https://github.com/IndEcol/Dashboard}.

```{r open-data, fig.height=2, fig.cap="The growing research interest in open data since its first occurrence in 1995 until 2014. Data from the Scopus analysis tool, from searching titles, abstracts and keywords for '\\texttt{open data}' or '\\texttt{open-data}'. \\label{fig:open_data}"}

open_data <- read.csv("04_database/open-data-research.csv")

library(MASS)
rate <- fitdistr(open_data$Number, "exponential")

library(dplyr)
open_data <- filter(open_data, Year>=1995)

library(ggplot2)
plot_open_data <- ggplot(open_data, aes(Year, Number)) +
  theme_bw() +
  ylab('Number of publications') +
  theme(axis.title.x = element_blank()) +
  geom_point()
plot_open_data
```

## Assembling a database of resource conversion processes

The database will include as many processes as feasibly possible which could be defined as a node in the middle of an urban system. To build the database, this chapter will adopt principles from technology scanning, however for these purposes, this procedure will be renamed to 'process scanning' which is more appropriate for the larger-scale activities (which may involve more than one technology) that provide energy, water and waste management services in cities (such as a wastewater treatment plant). The methodology is adapted from @Martland2002's two-stage approach: first, the general search stage systematically searches academic literature to identify the processes; second, the process mapping stage gathers data on each process to assemble the database.

### Systematic literature search (the general search)

This systematic literature search uses online search engines, together with the Bash and R programming languages to identify relevant processes from the literature available online, following the procedure below:

1. *Assemble the titles of relevant journals.* The titles of all the journals listed with the Thomson Reuters Master Journal List[^WebOfScienceURL] were downloaded (at the time of download there were 17,614 journals). This list was then reduced to a list of relevant journals, using an automated search to remove journal titles which contained no words that matched words from a list of keywords[^GitHub-journals]. The list of journal titles was subsequently reduced to 379 by manually removing the rest of the irrelevant content.
2. *Filter journals by impact.* This step reduced the literature to a manageable volume, which represents the highest quality research. First any journals with impact factors less than 0.5 were removed. From the remaining journals, top 75 percent of the 'impact' was retained by ranking the journals from highest to lowest according to their impact factor, and calculating a cumulative sum of their impact factors, and then removing all journals in the bottom 25 percent. This left 168 journals remaining.
3. *Find relevant journal articles.* Using the Web of Science search facility, the list of journals were searched for articles containing specified combinations of keywords[^GitHub-articles] which indicate they could include content related to urban resource management processes. This searched found 9,929 paper titles which were reduced to 7,681 titles after manual filtering.
4. *Article categorisation and further filtering by impact.* The article titles were then searched for keywords that enabled reorganisation of the articles into categories representing either a process or a resource. Each category was then divided into sub-categories. For example, the `effluent` category (a resource) contained sub-categories on `agriculture`, `fermentation`, `hydrogen` and `wastewater` amongst others. Each sub-category is therefore a list of journal articles whose titles contain both the word 'effluent' and the sub-category heading. This resulted in 65 main categories with a combined total of 955 sub-categories. Finally, the lowest impact categories were removed, by calculating each category's mean article impact factor (totaling the impact factors of each article in a category before dividing by the number of articles in the category), then ranking the categories from highest to lowest mean impact, and removing categories in the bottom 33 percent. This filtering left 4,747 unique article titles, thus making the process mapping stage more manageable.

[^GitHub-journals]: The keywords are available at \url{https://github.com/tomravalde/metabolism-database/tree/master/literature-search/keywords-journals.txt}
[^GitHub-articles]: The keywords are available at \url{https://github.com/tomravalde/metabolism-database/tree/master/literature-search/keywords-articles.txt}

<!--
Terminal commands for getting the number of unique article title in the final step of the above process

for i in $(find . -name "*.csv" | grep -v processes); do echo $i; cat $i >> file.out; done
sort file.out > sorted.out
uniq sorted.out > uniqe.out
-->

[^WebOfScienceURL]: \url{http://science.thomsonreuters.com/cgi-bin/jrnlst/jlresults.cgi?PC=MASTER}

### Data collection and database assembly (process mapping) {#sec:process-mapping}

Having categorised the processes and resources, each category was manually searched for articles which refer to processes that manage energy, water or waste. For example, if an article referred to a fuel cell which treats landfill leachate, this would lead to a search for information to describe the leachate treatment process, first studying the original article, and then if necessary other literature. Information on each process was recorded using the YAML[^YAML] format. YAML uses mappings to relate a value to a key. Mappings can be nested like sub-points and sub-sub points (and so on) in a bullet-point list by using a mapping-of-mappings, thus multiple layers of information can be attributed to any mapping. Moreover, YAML uses very lightweight syntax and is therefore human-readable when compared to other similarly structured data storage formats (such as JSON and XML). Furthermore, YAML data can easily be converted into other formats. The main keys making up a process's YAML file are as follows:

[^YAML]: 'YAML Ain't Markup Language': \url{yaml.org}

\begin{description}
\item[\texttt{process}] identifies the process name. For some processes, there exist a few variants, with different \texttt{capacity} values (see below); thus this key distinguishes these variants from one another by specifying both the process name (e.g. \texttt{anaerobic-digestion-wastewater}) and its capacity (e.g. \texttt{557} kg/s).
\item[\texttt{flow}] contains a list of mappings which specify the quantities of energy, water and waste consumed and produced by the process. Data on resource flow quantities come from process descriptions, inventories, and process mass and energy balances in the literature. Each flow contains another list of mappings comprising three items: the numerical quantity of the flow (which is negative for a process input and positive for a process output), the units (MW for energy quantities, and kg/s for everything else), and a reference to the information source.
\item[\texttt{trl}] defines the  `technology readiness level' (TRL) which is used to assess a technology's maturity, from the initial stages of scientific research to its implementation in the real world \citep{Mai2015}. TRLs were initially developed by NASA as a nine-point scale, but other organisations such as the U.S. Department of Defense use different scales \citep{Mankins2009}. This thesis uses its own simplified TRL definitions which define a process as `current' (9 on NASA's scale, for processes found commonly); `rare' (also 9 on NASA's scale, where processes exist in only a few places); `mid-term' (5--8 on NASA's scale, for processes which might have working pilots); or `long-term' (1--4 on NASA's scale, for those processes which only exist in the literature or the laboratory). For each process, this information was found by searching the literature and other online content. Sub-mappings record a justification of the TRL value attributed to a process, and a reference to the source of the justification.
\item[\texttt{main}] specifies which resource is considered the main input or output. For a power plant, this would be the electricity output; for a wastewater treatment plant, this would be the wastewater input. All the resource flow quantities are normalised with respect to this value, such that its magnitude equals 1.
\item[\texttt{capacity}] specifies the maximum rate at which the process can consume or produce the main resource. For example, for a 350 MW power plant, capacity would take a value of 350. Due to the normalisation of the flows with respect to the main resource, any process's resource flow multiplied by its capacity will provide the maximum rate of consumption or production of any resource for the process. This item contains two mappings specifying both a value and a reference.
\end{description}

The database is available as a GitHub repository at \url{https://github.com/tomravalde/metabolism-database}. An example database record is given in Figure \ref{fig:yaml}.

\begin{figure}
\lstinputlisting[language=yaml]{04_database/powerplant-paper-edit.yaml}
\caption{An example YAML record for a coal-fuelled powerplant.}
\label{fig:yaml}
\end{figure}

## Database overview and possible applications

```{r database-analysis}

# Import and shape data so we can obtain summary statistics

processes <- read.csv("04_database/processes-analysis.csv")

## Specifiy whether flows are inputs or outputs
processes$sign <- "Input"
processes[processes$value>0, ]$sign <- "Output"

## Add 'mainOutput' column

### Build mainOutput lookup table
lookup <- filter(processes, value==1)
lookup <- dplyr::select(lookup, c(process, resource))

### Use keyFlows.lookup to add 'mainOutput' column to proc.keyFlows
processes <- inner_join(processes, lookup, by="process")
colnames(processes)[colnames(processes)=="resource.x"] <- "resource"
colnames(processes)[colnames(processes)=="resource.y"] <- "mainOutput"

processes <- processes[,c("process",
			 "process.name", 
			 "capacity", 
			 "TRL", 
			 "resource",
			 "unit",
			 "value",
			 "sign",
			 "mainOutput")]
processes <- unique(processes) # TODO: fudge required, due to the duplication of each row when using inner_join (not sure why), so try and fix this.

write.csv(processes, "04_database/shiny-processes.csv")

```

The database currently contains `r length(unique(processes$process))` unique processes (or `r length(unique(processes$process.name))` when the different capacities are counted). These processes all manage energy, water and waste, encompassing `r length(unique(processes$resource))` resource types, of which 25 are main resources. Processes where energy resources are the main output include fossil fuel- and renewable-based generation technologies (such as power plants and concentrating solar power), as well as methods to produce biofuels and hydrogen. Where water resources are the main output, processes include the delivery and treatment of groundwater and surface water for potable and non-potable purposes. The waste management processes include treatment and energy extraction methods for many waste types including wastewaters, agricultural wastes, municipal solid waste and landfill leachate. Of the `r length(unique(processes$process))` unique processes, `r length(unique(filter(processes, TRL %in% c("c", "r"))$process))` are current, although `r length(unique(filter(processes, TRL=="r")$process))` of these have been identified as having low levels of market penetration (rare). The remaining `r length(unique(filter(processes, !TRL %in% c("c", "r"))$process))` are still in the research and development stage.

A central claim of this thesis is that a process-oriented perspective on UM could offer insight on how changing a system's mix of processes could meet demand for energy, water and waste management, but with reduced negative impacts. This database facilitates this a few ways, as described in the following three subsections.

### Process comparison

First, consider how processes meet demand for a single resource, using the subset of processes whose main output is methane as an example. Figure \ref{fig:heatmap_CH4} visualises the resource inputs and outputs for six processes to produce 1 kg of methane. At a glance, the proximity of points to the $\mbox{\textsf{Quantity}}=0$ intercept makes evident which production methods have the smallest of the various input and output flows. Coupling these flow values with the impact categories used in life cycle analysis and/or the constraints associated with a specific area would identify the most desirable process choice under certain circumstances. For example, a city which uses the very water-reliant 'Biogas upgrading -- AWR' method may like to consider lower water alternatives. Alternatively, another city may have a ready supply of biomass (perhaps from agricultural waste), which would otherwise go to waste, but could instead feed the gasification process. This latter example is one of the 'medium-term' processes, and therefore would require research and investment if it was to be implemented.

```{r energy-heatmap, fig.height=6, fig.cap="Resource consumption (negative values) and production (positive values) for different processes producing 1 kg of methane. Key: \\textsf{AWR} = alkaline with regeneration, \\textsf{BABIU} = bottom ash upgrading, \\textsf{HPWS} = high pressure water scrubbing; text labels indicate the TRL for each process.\\label{fig:heatmap_CH4}"}

## Extract subset of processes which produce methane as a main output
processes_CH4 <- filter(processes,
			mainOutput=="methane",
			capacity %in% c(0.24, 0.0001319, 0.122))

## Add more reader-friendly process and resource names for the plot
plot_names_processes <- read.csv("04_database/plot_names_processes.csv")
plot_names_resources <- read.csv("04_database/plot_names_resources.csv")

processes_CH4 <- inner_join(processes_CH4, plot_names_processes, by="process")
processes_CH4 <- inner_join(processes_CH4, plot_names_resources, by="resource")

processes_CH4$TRL <- factor(processes_CH4$TRL,
			    levels = c("c", "r", "m", "l")) # More appropriate order for the facets of the plot

## Add more descriptive TRL labels to the database
TRL <- c("c", "r", "m", "l")
TRL_name <- c("current", "rare", "medium-term", "long-term")
TRL_name_lookup <- data.frame(TRL, TRL_name)
processes_CH4 <- inner_join(processes_CH4, TRL_name_lookup, by="TRL")

en_dot <- ggplot(processes_CH4, aes(value, plot_name.y)) +
  theme_bw() +
  theme(axis.text.y = element_text(size=8),
	axis.title.y = element_blank(),
	strip.text = element_text(size=8)) +
  geom_point() +
  xlab("Quantity [kg or MJ]") +
  geom_vline(xintercept=0) +
  facet_wrap(~ plot_name.x, ncol=2) +
#  geom_text(aes(x=-23, y=1.5, label=TRL_name), size=3, hjust=0)
  geom_text(aes(label=TRL_name), x=-23, y=1.5, size=3, hjust=0)
en_dot
```

### Synergies in process networks

The methane production example above demonstrates the resource transfers which can take place between the energy, water, waste and other sectors. Figure \ref{fig:heatmap_CH4} shows how methane production (an energy resource) can result in energy flows (such as electricity or heat requirements), water flows (such as water inputs) and waste flows (such as vegetable waste inputs and digestate outputs). Inter-sectoral links such as these occur frequently in the database, and are summarised in Figure \ref{fig:sna_interactions}, which reveals numerous processes that link the energy, water, waste and other sectors. These links are are central to this thesis, because these are what the model will later optimise; namely, the use of one process's wastes and by-products as inputs to another. Consider the simple example of the material flows in an Indian village reported by @Kestemont2010. A material flow analysis of the village indicates it has both biomass waste outputs and electricity imports. Searching the database revealed 22 processes which have biomass inputs and electricity outputs (including biomass-fuelled CHP plants, straightforward combustion or biomass-to-ethanol conversion processes and in the medium term, fuel-cells). The village could invest in one of these processes, to reduce their expenditure on electricity imports. Some options could even produce other resources, such as methane or heat which can be used elsewhere in the village or sold. However, these benefits must be traded off against the resource input requirements (e.g. for coal or water) and economic decisions (e.g. payback time).

Another way to identify synergies is inspired by @Zhu2014's matchmaking proposal using the publicly available E-PRTR dataset introduced in Section \ref{sec:open-data}. Searching this dataset reveals that methane and CO$_2$ are both common pollutants (produced by 1,623 and 2,153 European industrial facilities respectively, from a total of 32,368 facilities). The database here lists 13 processes which require methane or CO$_2$ inputs, and thus could be used to redirect harmful emissions towards benificial purposes such as electricity production, algae cultivation and wastewater treatment.


```{r interaction-network}

# Inter-sectoral plot for whole network stored separately, so it's easy to suppress from paper compilation (to save time)
base::source("04_database/resource-network.R")

resource_sectors <- read.csv("04_database/resources-sector.csv")
sectors_lookup <- rbind(c("energy", "blue"),
			c("water", "red"),
			c("waste", "black"),
			c("other", "green"))
sectors_lookup <- data.frame(sectors_lookup)
colnames(sectors_lookup) <- c("sector", "node_vector")
resources_sectors_node <- inner_join(resource_sectors, sectors_lookup)
node_vector <- c(resources_sectors_node$node_vector)

## Network plot (using SNA package)
layout <-  c("fruchtermanreingold", "kamadakawai", "spring", "circle", "eigen", "hall", "mds", "princoord", "target")

#library(sna) # Code to plot figure for saving (and subsequent manual editing)
#gplot(link_matrix,
#      mode=layout[1],
#      gmode="graph",
#      label = resources,
#      label.pos = 1,
#      jitter=FALSE,
##      arrowhead = FALSE,
#      thresh=0,
##      vertex.sides = 0,
#      vertex.col = node_vector,
#      edge.col = rgb(220, 217, 217, maxColorValue=255),
#      displaylabels = TRUE)
```

\begin{figure}
	\centering
	\begin{spacing}{1.0}
	\includegraphics[width=\columnwidth]{04_database/final-network.pdf}
	\end{spacing}
	\caption{The interactions of resources in the database. The proximity of any pair of connected resources is proportional to the number of processes for which one resource of the pair is an input, and the other is an output. This graph is plotted using the R package from \citet{SNA2005}.}
	\label{fig:sna_interactions}
\end{figure}

### Optimisation of networks

Considering the possibilities for inter-sectoral synergies in the ad-hoc manner above is impossible when expanding to the city scale. Chapter 1 argued from this for the need for systems thinking, in which the processes and resources are represented formally, such that mathematical techniques can find the optimal system configuration (Section \ref{sec:systems-optimisation}. This modelling approach will be more fully realised through the optimisation model developed and applied in the next two chapters. However, as a preview, an early version of the model (described in @Ravalde2015) will provide a simple demonstration of how the database could be used in a simple optimisation. In this model, the user specifies the time and location of resource demands and waste generation rates, and a mathematical optimisation routine identifies the mix of processes that meets a city's demands whilst minimising an objective (such as cost, carbon footprint, water footprint, waste generation etc.).

The example is based on the hypothetical city of @Wolman1965, using his data to derive bottom-up demands for electricity, heating[^wolman_energy] and water (motor fuel and food from his paper are ignored), and generation rates for refuse and wastewater. Making all the technologies in the database available, the city's choice of processes was optimised to minimise CO$_2$ emissions. Figure \ref{fig:bar_wolman} shows the city's resource flows at the top, both before and after optimisation. The model was able to cut emissions to zero, by choosing gas-fuelled CHP to meet energy demands (which requires a slight increase in gas imports, but eliminates coal and oil imports). The model also chooses algae cultivation to absorb any remaining emissions. Sewage flows are also reduced while refuse and water flows remain unchanged. These system changes are unlikely in reality because of constraints on land-use (e.g. for algae production) and cost, nevertheless this example demonstrates the potential benefits of process-oriented optimisation modelling.

[^wolman_energy]: It is assumed that the fossil fuels (coal, natural gas and oil) meet all electricity and heating demand, and that electricity consumption is 1.12 times the heat consumption (this value is calculated from the mean ratio of electrity-to-heat consumption for all cities in the UM database from @Kennedy2014).

```{r wolman-flows, fig.height=3.6, fig.cap="Aggregate metabolic flows at the top of Wolman's hypothetical city before and after optimisation modelling proposes an optimal network for the system's middle. Negative values represent inputs into the city boundary, while positive values represent outputs\\label{fig:bar_wolman}."}

wolman <- read.csv("04_database/wolman-flows.csv")
wolman <- melt(wolman)

plot_wolman <- ggplot(wolman, aes(resource, -value/1e6)) +
  theme_bw() +
#  geom_bar(stat="identity") +
  geom_point() +
  geom_hline(xintercept=0) +
  coord_flip() +
  xlab("Resource (units)") + 
  ylab("Value [units x 10^6]") +
  facet_wrap(~variable, ncol=1)
plot_wolman
```

An optimisation model for a city can explore different aspects to process-oriented planning and policy agendas. For example, it can inform urban planning by considering whether decentralised systems (which use more smaller capacity processes close to the point of resource use or generation) manage resources more efficiently than centralised systems. Modelling could also inform how a system's middle should adapt to changes at the bottom, by altering resource demands to simulate behavioural changes and efficiency measures. Finally, in conjunction with this database, the model can help clarify research and investment efforts, by identifying which processes with medium- and long-term TRLs would most help an urban area achieve some particular objective.

### Reflections: interacting with other datasets

The three applications above each depend on the availability of other data: process comparisons require knowledge of resource inputs and outputs in an existing process; searching for synergies requires knowledge of inputs and outputs to multiple processes; and optimisation modelling needs to know the resource demands and waste generation rates at the bottom of an entire system.

Thus a potential obstacle to using the database is the availability of other data. @Davis2010 argues that within IE, data is often "unavailable, inaccessible, incomplete, incompatible, or unreliable" (p.708), and believes that IE can best overcome these obstacles through increased collaboration. Here, the use of other open source datasets has been limited to the E-PRTR, but it would be profitable to reach beyond this source and use data more associated with UM to identify synergies between energy conversion, water treatment and waste management processes in existing cities. Similarly, a dataset of demands for electricity, heating, potable and non-potable water, and waste and wastewater management could be established for domestic, commercial and industrial sectors, for real urban areas of different types (such as size, maturity and climate). It would also be beneficial to have some means of linking databases together. @Davis2010 elucidate this by recapitulating the arguments of @Bush1945 concerning the most useful ways to store scientific knowledge. Rather than traditional hierarchical storage (e.g alphabetical order or the Dewey Decimal System) which forces all information into a single location, @Bush1945 argued that information should be located according to associative trails, i.e. paths "where facts are connected to other associated facts" [@Davis2010, p.711], as exemplified by Wikipedia's use of hyperlinks. @Davis2010 take on board Bush's concept, and note that it can be facilitated within IE by using Semantic wikis (of which Enipedia is an example), which store information in both structured and unstructured formats. Unstructured information uses prose (such as the history of a particular process); structured information records machine-readable quantitative information (such as a resource flow value, a capacity or a TRL). Information can contain hyperlinks that point to other relevant pages.

The Semantic Web (of which Semantic wikis are a part) has attracted some scepticism, largely due to pragmatic concerns. Any machine readable information needs to be encoded according to some standard, which may not be agreed upon by the different parts of a community, and conforming to multiple different standards would incur a high financial and resource cost [@Marshall2003]. However, @Herman2007 has observed that the Semantic Web has been successful within specialised communities (such as financial services and health care); thus there is promise for it within IE. Furthermore, to minimise the efforts required by contributors, machine learning has the potential to automate the searching of information to discover structure within it, and then to formally encode this structure with the appropriate Semantic Web code [@Tresp2008].

@Davis2010 illustrate how a Semantic wiki could assist a hypothetical life cycle analysis researcher. Inspired by this example, consider the following illustration of UM research might benefit from the database assembled here. Imagine that the 'Biogas upgrading -- AWR' processes information (Figure \ref{fig:heatmap_CH4}) was part of a Semantic Wiki.  Its wiki page could use unstructured data to describe how it works (perhaps including details on the process chemistry), and use structured data to record the resource inputs and outputs. The text of the resource flow of `Water -- non-potable` would be a hyperlink to a page about non-potable water. This page could then link to another page which lists the all processes which produce `Water -- non-potable` (both from the database, and other sources), which could then link to a page which lists all the cities which currently use such processes. Thus a researcher can navigate through several datasets (including that of this chapter) to find possible applications of technologies in the database.

## Summary and further work {#sec:database-conclusions}

As the thesis has earlier argued, there is a need for models which can improve an area's metabolism by optimising the network of processes which convert and transport energy, water, and waste. Such a model provides a process-oriented view of UM, and requires data on the properties and performance of resource management processes. This is provided by the database assembled here, which comprises 202 unique processes that manage energy, water and waste, both currently operational and those still in research and development. A few example applications of the database have shown ways to inform decision makers how best to plan and invest in processes which improve a city's metabolism. This can be to choose the best of several alternatives to manage a single resource (in the case of a single utility service provider); to choose processes which take advantage of potential synergies in an area (in the case of a cooperative of organisations), or to optimise a city's whole network of processes (which is the main objective of this thesis).

This database is a novel contribution to the UM and IE field, and the information it provides to decision makers will improve as the research community takes advantage of database's open data format to continually improve it, in the following ways:

1. Adding new processes
2. Broadening the type of information each process records, to include process costs (for capital, operation and maintenance), and other pollutants (such as SO$_2$), and other data.
3. Extending the database beyond energy, water and waste management processes, to consider other processes which affect the metabolism of an area, such as steel and concrete manufacturing.

Another area of future work is to support not just the evolution of the database, but of the whole ecosystem in which it lives. This is because process-oriented approaches to UM study are not isolated from other approaches, but rather are most useful when using information from them, such as demand data from the bottom of a UM system. The UM data ecosystem could flourish in the Semantic Web, which can link together structured and unstructured information in a vast network, through which researchers can navigate, finding innovative and as yet unknown applications for the data. The database is publicly available under an open-source licence and so it is hoped that it will become part of an evolving ecosystem of linked UM data.

In summary, the database can facilitate process-oriented approaches to UM, especially if it becomes part of an information ecosystem in which data from the top, middle and bottom of urban system are considered together in more holistic UM assessments. Ultimately, this will help cities meet their inhabitants' needs more sustainability, in response to the environmental and economic challenges challenges presented by urbanisation and its associated patterns of resource consumption.
